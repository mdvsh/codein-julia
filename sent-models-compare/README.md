# sent-models-compare

## ğŸ‘¨â€ğŸ’» Machine Learning Task ğŸ‘¨â€ğŸ’»

## Deliverable

Best task that I worked on !

<script src="https://gist.github.com/PseudoCodeNerd/493a3f477bd97fc15b24c853e7de7d9c.js"></script>

1. Notebooks
    - [TextAnalysis.jl](./SentimentAnalysis(julia).ipynb)
    - [Tensorflow](./comparing-sentanalysis-ii.ipynb)

2. [**Result**](https://github.com/JuliaText/TextAnalysis.jl/issues/187#issue-551462795)


3. [Gist](https://gist.github.com/PseudoCodeNerd/493a3f477bd97fc15b24c853e7de7d9c)

<hr>

## Compare SentimentAnalysis models

### Task Description

Use the[ amazon review data](https://www.kaggle.com/bittlingmayer/amazonreviews) from Kaggle to test the efficiency of our Sentiment Analysis models that live in [TextAnalysis.jl](https://github.com/JuliaText/TextAnalysis.jl). Compare it with models in ScikitLearn and Spacy python libraries. Upload your results as an issue in the TextAnalysis package.

Some basic machine learning knowledge is useful for this task.

<hr>